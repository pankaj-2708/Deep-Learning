{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length is the seq_len , depth is the embeding dim\n",
    "def positional_encoding(length, depth):\n",
    "    positions=np.arange(length)[:,np.newaxis]  # seq_len , 1\n",
    "    \n",
    "    depths=np.arange(depth)[np.newaxis , : ]  # 1, depth\n",
    "    \n",
    "    angle_rates=1/np.power(10000,(2 * depths // 2)) / depth\n",
    "    angles=positions*angle_rates    # pos , depth \n",
    "    angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
    "    angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
    "    \n",
    "    return tf.cast(angles,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae305c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.layer):\n",
    "    def __init__(self,vocab_size,d_model):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.embedding=Embedding(vocab_size,d_model,mask_zero=True)\n",
    "        # here pos_encoding are generated with length (seq_length) = 2048 \n",
    "        self.pos_encoding=positional_encoding(length=2048,depth=d_model)\n",
    "        \n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "       return self.embedding.compute_mask(*args, **kwargs)\n",
    "   \n",
    "    def call(self,x):\n",
    "        # x is input its shape will be  batch_size,seq_len\n",
    "        length=tf.shape(x)[1]\n",
    "        x=self.embedding(x)\n",
    "        # now x will be of shape batch_size,seq_len,embed_dim\n",
    "        \n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        x=x+self.positional_encoding[tf.newaxis,:length,:]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
