{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61874cf1",
   "metadata": {},
   "source": [
    "# Transformer Training Shape Walkthrough\n",
    "\n",
    "This file describes all tensor shapes during **training**, where the decoder receives the full target sequence at once (teacher forcing).  \n",
    "Notation:\n",
    "- B = batch size\n",
    "- I = encoder input length\n",
    "- O = decoder target length\n",
    "- E = embedding/model dimension\n",
    "- H = number of heads\n",
    "- FFN hidden dimension = 2048\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Encoder (Training)\n",
    "\n",
    "## Input\n",
    "```\n",
    "(B, I)\n",
    "```\n",
    "\n",
    "## Embedding + Positional Encoding\n",
    "```\n",
    "(B, I, E)\n",
    "```\n",
    "\n",
    "## Self-Attention Block\n",
    "\n",
    "### Q, K, V projections\n",
    "```\n",
    "Q = (B, I, E)\n",
    "K = (B, I, E)\n",
    "V = (B, I, E)\n",
    "```\n",
    "\n",
    "### Split across heads\n",
    "```\n",
    "(B, H, I, E/H)\n",
    "```\n",
    "\n",
    "### Scaled dot-product\n",
    "Scores:\n",
    "```\n",
    "(B, H, I, I)\n",
    "```\n",
    "\n",
    "Attention output:\n",
    "```\n",
    "(B, H, I, E/H)\n",
    "```\n",
    "\n",
    "Concat heads:\n",
    "```\n",
    "(B, I, E)\n",
    "```\n",
    "\n",
    "Final linear:\n",
    "```\n",
    "(B, I, E)\n",
    "```\n",
    "\n",
    "Residual + LayerNorm:\n",
    "```\n",
    "(B, I, E)\n",
    "```\n",
    "\n",
    "## Feed-Forward Network\n",
    "```\n",
    "(B, I, 2048) → (B, I, E)\n",
    "```\n",
    "\n",
    "Residual + LayerNorm:\n",
    "```\n",
    "(B, I, E)\n",
    "```\n",
    "\n",
    "Encoder output:\n",
    "```\n",
    "(B, I, E)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Decoder (Training Mode, Full Sequence Provided)\n",
    "\n",
    "## Input target tokens\n",
    "```\n",
    "(B, O)\n",
    "```\n",
    "\n",
    "## Embedding + Positional Encoding\n",
    "```\n",
    "(B, O, E)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# A. Masked Self-Attention\n",
    "\n",
    "### Q, K, V\n",
    "```\n",
    "(B, O, E)\n",
    "```\n",
    "\n",
    "### Split into heads\n",
    "```\n",
    "(B, H, O, E/H)\n",
    "```\n",
    "\n",
    "### Scores\n",
    "```\n",
    "(B, H, O, O)\n",
    "```\n",
    "\n",
    "(Causal mask applied)\n",
    "\n",
    "### Output\n",
    "```\n",
    "(B, O, E)\n",
    "```\n",
    "\n",
    "Residual + LayerNorm:\n",
    "```\n",
    "(B, O, E)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# B. Cross-Attention  \n",
    "\n",
    "Q from decoder:\n",
    "```\n",
    "(B, O, E)\n",
    "```\n",
    "\n",
    "K, V from encoder:\n",
    "```\n",
    "(B, I, E)\n",
    "```\n",
    "\n",
    "### Head split\n",
    "```\n",
    "Q: (B, H, O, E/H)\n",
    "K: (B, H, I, E/H)\n",
    "V: (B, H, I, E/H)\n",
    "```\n",
    "\n",
    "### Scores\n",
    "```\n",
    "(B, H, O, I)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "(B, O, E)\n",
    "```\n",
    "\n",
    "Residual + LayerNorm:\n",
    "```\n",
    "(B, O, E)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# C. Feed-Forward Network\n",
    "```\n",
    "(B, O, 2048) → (B, O, E)\n",
    "```\n",
    "\n",
    "Residual + LayerNorm:\n",
    "```\n",
    "(B, O, E)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Final Linear + Softmax\n",
    "\n",
    "Logits:\n",
    "```\n",
    "(B, O, Vocab)\n",
    "```\n",
    "\n",
    "Loss is computed against target labels of shape:\n",
    "```\n",
    "(B, O)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# Summary Table\n",
    "\n",
    "| Stage | Shape |\n",
    "|-------|--------|\n",
    "| Encoder input | (B, I) |\n",
    "| Encoder output | (B, I, E) |\n",
    "| Decoder input | (B, O) |\n",
    "| Decoder output before linear | (B, O, E) |\n",
    "| Final logits | (B, O, Vocab) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecb4429",
   "metadata": {},
   "source": [
    "# Transformer Inference Shape Walkthrough\n",
    "\n",
    "## Encoder (Inference Same as Training)\n",
    "- Input: `(1, I)`\n",
    "- Embedding + Positional: `(1, I, E)`\n",
    "- Encoder output: `(1, I, E)`\n",
    "\n",
    "---\n",
    "\n",
    "# Decoder – Autoregressive Inference\n",
    "\n",
    "## Step 1 — First Token\n",
    "decoder receives:\n",
    "[sos]\n",
    "- Decoder input: `(1,1)`\n",
    "- Embedding: `(1,1,E)`\n",
    "- Masked self-attention: `(1,1,E)`\n",
    "- Cross-attention: `(1,1,E)`\n",
    "- FFN: `(1,1,E)`\n",
    "- Final logits: `(1,1,Vocab)`\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2 — Second Token\n",
    "Now decoder receives:\n",
    "[sos, predicted_token_1]\n",
    "\n",
    "- Decoder input: `(1,2)`\n",
    "- Embedding: `(1,2,E)`\n",
    "- Masked self-attention: `(1,2,E)`\n",
    "- Cross-attention: `(1,2,E)`\n",
    "- FFN: `(1,2,E)`\n",
    "- Final logits: `(1,2,Vocab)` (only last position used)\n",
    "\n",
    "---\n",
    "\n",
    "## General Step t\n",
    "- Decoder input: `(1,t)`\n",
    "- Embedding: `(1,t,E)`\n",
    "- Masked self-attention: `(1,t,E)`\n",
    "- Cross-attention: `(1,t,E)`\n",
    "- FFN: `(1,t,E)`\n",
    "- Final logits: `(1,t,Vocab)` → use `(1,Vocab)`\n",
    "\n",
    "---\n",
    "\n",
    "## Final Output for O Tokens\n",
    "- Output tokens: `(1,O)`\n",
    "- Final logits: `(1,O,Vocab)`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
