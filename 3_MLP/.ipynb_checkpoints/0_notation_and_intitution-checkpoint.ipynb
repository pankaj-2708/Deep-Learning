{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2db07c62-21dd-412b-a876-2e8f080b5940",
   "metadata": {},
   "source": [
    "# \"MLP Notation\"\n",
    "lec 8 campus x\n",
    "\n",
    "***\n",
    "\n",
    "### Lecture Notes: Multi-layer Perceptron (MLP) Notation\n",
    "\n",
    "**1. Introduction and Importance of Notation**\n",
    "*   This video builds on previous discussions about Multi-layer Perceptron (MLP) intuition, exploring how MLPs work and why they are effective.\n",
    "*   The most challenging aspect of understanding MLPs is often the **training algorithm, known as Backpropagation**.\n",
    "*   A common source of confusion when learning backpropagation is the large number of weights and biases in a neural network. Without a proper system for notation, it becomes difficult to distinguish between these parameters, leading to confusion during complex calculations.\n",
    "*   **The primary goals of this video are**:\n",
    "    1.  To learn how to **calculate the total number of trainable parameters** (weights and biases) in any given neural network architecture.\n",
    "    2.  To establish a **standardised notation for weights, biases, and outputs** that is commonly followed in the industry, to avoid confusion during backpropagation.\n",
    "\n",
    "**2. Neural Network Architecture Setup**\n",
    "\n",
    "<img src='https://i.ibb.co/twpX7JCM/image.png'>\n",
    "\n",
    "*   The lecture uses a specific neural network architecture for demonstration. (shown above)\n",
    "*   This architecture consists of **four layers in total**:\n",
    "    *   **Layer 0**: The Input Layer.\n",
    "    *   **Layer 1**: The first Hidden Layer.\n",
    "    *   **Layer 2**: The second Hidden Layer.\n",
    "    *   **Layer 3**: The Output Layer.\n",
    "*   The input data for this example is **four-dimensional**, meaning each input instance has four features or columns.\n",
    "\n",
    "**3. Calculating Trainable Parameters (Weights and Biases)**\n",
    "*   **Trainable parameters** are the values of weights and biases that the backpropagation algorithm will determine during the training process of the model.\n",
    "*   It is crucial to be able to calculate these from any given architecture.\n",
    "*   **For the demonstrated architecture**:\n",
    "    *   **From Input Layer (Layer 0) to Hidden Layer 1 (Layer 1)**:\n",
    "        *   Layer 0 has 4 nodes and Layer 1 has 3 nodes.\n",
    "        *   **Weights**: 4 (nodes in Layer 0) × 3 (nodes in Layer 1) = **12 weights**.\n",
    "        *   **Biases**: 3 (biases, one for each node in Layer 1).\n",
    "        *   *Subtotal for this segment*: 12 weights + 3 biases = **15 parameters**.\n",
    "    *   **From Hidden Layer 1 (Layer 1) to Hidden Layer 2 (Layer 2)**:\n",
    "        *   Layer 1 has 3 nodes and Layer 2 has 2 nodes.\n",
    "        *   **Weights**: 3 (nodes in Layer 1) × 2 (nodes in Layer 2) = **6 weights**.\n",
    "        *   **Biases**: 2 (biases, one for each node in Layer 2).\n",
    "        *   *Subtotal for this segment*: 6 weights + 2 biases = **8 parameters**.\n",
    "    *   **From Hidden Layer 2 (Layer 2) to Output Layer (Layer 3)**:\n",
    "        *   Layer 2 has 2 nodes and Layer 3 has 1 node.\n",
    "        *   **Weights**: 2 (nodes in Layer 2) × 1 (node in Layer 3) = **2 weights**.\n",
    "        *   **Biases**: 1 (bias, for the node in Layer 3).\n",
    "        *   *Subtotal for this segment*: 2 weights + 1 bias = **3 parameters**.\n",
    "    *   **Total Trainable Parameters for the entire network**: 15 + 8 + 3 = **26 parameters**. This means the backpropagation algorithm will find the values for these 26 weights and biases.\n",
    "\n",
    "**4. Notation for Biases (b)**\n",
    "*   The notation for biases is straightforward and uses two indices.\n",
    "*   **Standard Notation**: **`b_i^j`**\n",
    "    *   **`i`**: Represents the **layer number**.\n",
    "    *   **`j`**: Represents the **node number** within that layer.\n",
    "*   **Examples**:\n",
    "    *   **`b_1^1`**: Bias for the first node in Layer 1.\n",
    "    *   **`b_1^2`**: Bias for the second node in Layer 1.\n",
    "    *   **`b_2^1`**: Bias for the first node in Layer 2.\n",
    "    *   **`b_3^1`**: Bias for the first (and only) node in Layer 3.\n",
    "\n",
    "**5. Notation for Outputs (o)**\n",
    "*   The notation for outputs is identical to that for biases.\n",
    "*   **Standard Notation**: **`o_i^j`**\n",
    "    *   **`i`**: Represents the **layer number**.\n",
    "    *   **`j`**: Represents the **node number** within that layer.\n",
    "*   Any output originating from a node will follow this notation.\n",
    "*   **Examples**:\n",
    "    *   **`o_1^1`**: Output from the first node in Layer 1.\n",
    "    *   **`o_1^2`**: Output from the second node in Layer 1.\n",
    "    *   **`o_2^1`**: Output from the first node in Layer 2.\n",
    "    *   **`o_3^1`**: Output from the first (and only) node in Layer 3.\n",
    "\n",
    "eg - \n",
    "<img src='https://miro.medium.com/v2/resize:fit:1400/1*2vLiWsyesKLAfDcezIfBRQ.png'>\n",
    "\n",
    "**6. Notation for Weights (W)**\n",
    "*   The notation for weights is slightly more complex, requiring three indices.\n",
    "*   **Standard Notation**: **`W_k_i^j`**\n",
    "    *   **`k`**: Represents the **layer number that the weight is entering**. This is the layer containing the destination node.\n",
    "    *   **`i`**: Represents the **node number in the previous layer from which the weight is originating**.\n",
    "    *   **`j`**: Represents the **node number in the current layer (layer `k`) that the weight is entering**.\n",
    "*   **Examples (referencing the network diagram in the source)**:\n",
    "    *   **`W_1_1^1`**: Weight entering **Layer 1**, originating from the **1st node of the previous layer** (Layer 0), and entering the **1st node of Layer 1**.\n",
    "    *   **`W_1_4^2`**: Weight entering **Layer 1**, originating from the **4th node of the previous layer** (Layer 0), and entering the **2nd node of Layer 1**.\n",
    "    *   **`W_1_1^3`**: Weight entering **Layer 1**, originating from the **1st node of the previous layer** (Layer 0), and entering the **3rd node of Layer 1**.\n",
    "    *   **`W_2_2^2`**: Weight entering **Layer 2**, originating from the **2nd node of the previous layer** (Layer 1), and entering the **2nd node of Layer 2**.\n",
    "    *   **`W_3_1^1`**: Weight entering **Layer 3**, originating from the **1st node of the previous layer** (Layer 2), and entering the **1st node of Layer 3**.\n",
    "\n",
    "eg \n",
    "\n",
    "<img src='https://miro.medium.com/v2/resize:fit:1200/1*n5YNnh_vG2exS-YnjDPoPA.png'>\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa701451-b05f-459e-9e2e-c793c39ee4cd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
