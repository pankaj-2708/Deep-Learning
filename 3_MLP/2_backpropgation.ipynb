{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a7985d-5a55-41e9-926e-16d3e80816cf",
   "metadata": {},
   "source": [
    "# \"Backpropagation in Deep Learning | Part 1 | The What?\":\n",
    "\n",
    "campus x dl playlist \n",
    "\n",
    "---\n",
    "\n",
    "**Backpropagation in Deep Learning: The What? (Part 1)**\n",
    "\n",
    "**1. Introduction to Backpropagation**\n",
    "*   Backpropagation is considered **one of the most important topics in Deep Learning**.\n",
    "*   This video is the first in a three-part series, focusing on \"The What,\" meaning **understanding what backpropagation is**.\n",
    "*   The subsequent parts will cover \"The How\" (detailed mathematical calculations and coding with two datasets: regression and classification) and \"The Why\" (addressing questions arising from \"What\" and \"How\").\n",
    "\n",
    "**2. What is Backpropagation?**\n",
    "*   **Official Definition:** Backpropagation, short for \"backward propagation of errors,\" is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and a loss function, the method calculates the gradient of the error function with respect to the neural network's weights.\n",
    "*   **Simplified Definition:** It is an algorithm used to **train neural networks**.\n",
    "*   In simpler terms, for a given dataset, backpropagation **finds the most optimal values for the weights and biases** of a neural network, enabling it to make the best possible predictions.\n",
    "\n",
    "**3. Prerequisites for Understanding Backpropagation**\n",
    "To properly understand backpropagation, two topics should already be known:\n",
    "*   **Gradient Descent:** An optimisation algorithm.\n",
    "*   **Forward Propagation:** A technique used by neural networks to make predictions.\n",
    "\n",
    "**4. How Backpropagation Works: The Core Algorithm**\n",
    "Backpropagation follows a series of steps to find the correct values for weights and biases. Let's consider a simple neural network with three neurons, two inputs (CGPA, IQ), and one output (LPA prediction), where the connections represent weights and each neuron has a bias.\n",
    "\n",
    "**Step-by-Step Process:**\n",
    "\n",
    "*   **Step 0: Initialise Weights and Biases**\n",
    "    *   Before training begins, all weights and biases in the neural network are assigned initial values.\n",
    "    *   Different initialisation techniques exist (e.g., random values, setting all weights to 1 and all biases to 0).\n",
    "    *   For simplicity, in this explanation, all weights are initialised to **1**, and all biases to **0**.\n",
    "    *   It's assumed that a **linear activation function** is used in all nodes for this regression problem.\n",
    "\n",
    "*   **Step 1: Loop Through Students (Data Points)**\n",
    "    *   The algorithm operates by iterating through each student (data point) in the dataset.\n",
    "    *   This loop runs multiple times over the entire dataset; each complete pass through the dataset is called an **epoch**.\n",
    "\n",
    "*   **Step 2: Perform Forward Propagation and Get a Prediction**\n",
    "    *   For a selected student, their input data (e.g., CGPA and IQ) is fed into the neural network.\n",
    "    *   Using the current (initially random or set) weights and biases, the neural network calculates an output prediction (e.g., LPA).\n",
    "    *   This process is called **forward propagation**.\n",
    "    *   Initially, due to incorrect weights, the prediction will likely be inaccurate (e.g., actual LPA is 3 lakhs, but the network predicts 8 lakhs).\n",
    "\n",
    "*   **Step 3: Calculate the Loss (Error)**\n",
    "    *   A **loss function** is used to quantify the difference between the network's prediction (`y_hat`) and the actual target value (`y`).\n",
    "    *   For a regression problem, **Mean Squared Error (MSE)** is often used: `L = (y - y_hat)^2`.\n",
    "    *   The calculated loss indicates how much error the network made for that specific data point. For example, if `y = 3` and `y_hat = 8`, `L = (3 - 8)^2 = 25`.\n",
    "\n",
    "*   **Step 4: Update Weights and Biases (The \"Backward\" Part)**\n",
    "    *   The goal is to **reduce the loss** by adjusting the weights and biases.\n",
    "    *   Since the true `y` (ground truth) cannot be changed, the network must change its `y_hat` prediction.\n",
    "    *   The `y_hat` prediction depends on the outputs of previous layers and ultimately on all the weights and biases in the network.\n",
    "    *   **The \"Back\" in Backpropagation:** To minimise the loss, changes need to be made to the weights and biases by **going \"backward\" through the network**, tracing how the loss is influenced by each parameter. This is why the algorithm is named \"backpropagation of errors\".\n",
    "\n",
    "    *   **Using Gradient Descent:** Weights and biases are updated using the **gradient descent optimisation algorithm**.\n",
    "        *   The update rule is: **`Weight_new = Weight_old - (Learning_Rate * Partial_Derivative_of_Loss_with_Respect_to_Weight)`**.\n",
    "        *   A similar rule applies to biases: **`Bias_new = Bias_old - (Learning_Rate * Partial_Derivative_of_Loss_with_Respect_to_Bias)`**.\n",
    "        *   The `Learning_Rate` is a small positive value (e.g., 0.1) that controls the step size of the update.\n",
    "\n",
    "    *   **Calculating Derivatives (Gradients):**\n",
    "        *   The crucial part is calculating the **partial derivatives (gradients)** of the loss function with respect to each weight and bias in the network. This involves understanding how a small change in a weight/bias affects the loss.\n",
    "        *   Since weights/biases often have an indirect effect on the final loss (e.g., `Loss` depends on `y_hat`, `y_hat` depends on `O_21`, `O_21` depends on `W_211`, `W_211` depends on `O_11`, etc.), the **Chain Rule of Differentiation** is applied.\n",
    "        *   For example, to find `∂L/∂W_211` (change in loss with respect to weight `W_211`), we would calculate `(∂L/∂y_hat) * (∂y_hat/∂O_11) * (∂O_11/∂W_211)`.\n",
    "        *   This process involves calculating **nine derivatives** for the example network (four weights in the first layer, two biases in the first layer, two weights in the second layer, and one bias in the second layer).\n",
    "        *   These derivatives are then plugged into the gradient descent update rule to adjust each weight and bias.\n",
    "\n",
    "*   **Repeating for All Students and Epochs:**\n",
    "    *   After updating weights and biases for one student, the loop goes to the next student, performs forward propagation, calculates loss, and updates weights/biases again.\n",
    "    *   This process continues until all students in the dataset have been processed.\n",
    "    *   This entire cycle (processing all students once) constitutes one **epoch**.\n",
    "    *   **Multiple epochs** (hundreds or thousands) are run until **convergence** is achieved, meaning the loss is minimised, and the network's predictions are accurate (e.g., the predicted LPA for a student is close to their actual LPA).\n",
    "\n",
    "**5. Conclusion of Part 1**\n",
    "*   This video explained **what backpropagation is** and its step-by-step working at a conceptual level, including the initialisation, forward pass, loss calculation, and the backward adjustment of weights and biases using gradient descent and the chain rule.\n",
    "*   The next video (\"The How\") will involve detailed mathematical calculations with a real dataset and converting those calculations into code to demonstrate how backpropagation effectively reduces loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73562694-0909-4eae-a7c5-a057be54e15d",
   "metadata": {},
   "source": [
    "# \"Backpropagation Part 2 | The How | Complete Deep Learning Playlist\":\n",
    "\n",
    "---\n",
    "\n",
    "**Backpropagation in Deep Learning: The How? (Part 2)**\n",
    "\n",
    "**1. Introduction**\n",
    "*   This video builds on \"The What\" (Part 1), now focusing on **\"The How\" of backpropagation**.\n",
    "*   The goal is to implement backpropagation from scratch using custom code on two types of datasets: a **regression problem** and a **classification problem**.\n",
    "*   This will provide a deeper understanding of how the algorithm works behind the scenes, including a comparison with Keras implementation.\n",
    "\n",
    "**2. Backpropagation for a Regression Problem**\n",
    "\n",
    "**2.1. Goal and Dataset**\n",
    "*   The objective is to **train a neural network** on a given dataset to predict a student's LPA (Lakhs Per Annum) based on their CGPA and Resume score.\n",
    "*   The training will be done **without using Keras**, by converting the backpropagation algorithm into custom code.\n",
    "*   **Dataset:** Similar to the one used in Part 1, but **IQ has been replaced with \"Resume Score\"** (ranging 0-10). This change ensures input features are in a similar range (CGPA 0-10, Resume 0-10), which is generally beneficial for neural network training.\n",
    "*   **Neural Network Architecture:** Remains the same as in Part 1:\n",
    "    *   Input Layer: 2 nodes (CGPA, Resume)\n",
    "    *   Hidden Layer: 2 nodes\n",
    "    *   Output Layer: 1 node (LPA prediction).\n",
    "*   **Activation Function:** For this regression problem, a **linear activation function** is assumed in all nodes.\n",
    "\n",
    "**2.2. The Training Loop (Epochs and Students)**\n",
    "The backpropagation algorithm involves nested loops:\n",
    "*   **Outer Loop (Epochs):** The training process is repeated for a specified number of epochs (e.g., 5 times). An epoch is one complete pass through the entire dataset.\n",
    "*   **Inner Loop (Students/Data Points):** Within each epoch, the algorithm iterates through each student (data point) in the dataset. This selection can be random, but for demonstration, a one-by-one sequential approach is used.\n",
    "\n",
    "**2.3. Step-by-Step Algorithm within the Inner Loop**\n",
    "\n",
    "*   **Step 0: Initialise Parameters (Weights and Biases)**\n",
    "    *   A custom function `initialize_parameters` is used to create and assign initial values to all 9 weights and biases of the neural network.\n",
    "    *   For the example, weights are initialised to `0.1` and biases to `0`.\n",
    "    *   The function returns:\n",
    "        *   `w1` (weights for the first layer, a 2x2 matrix)\n",
    "        *   `b1` (biases for the first layer, a 1x2 matrix)\n",
    "        *   `w2` (weights for the second layer, a 2x1 matrix)\n",
    "        *   `b2` (bias for the second layer, a 1x1 matrix).\n",
    "\n",
    "*   **Step 1: Forward Propagation and Prediction**\n",
    "    *   For the current student, their input data (X) is passed through the neural network using the current weights and biases.\n",
    "    *   A `linear_forward` function calculates the output of a single neuron by performing a dot product (`W * X`) and adding the bias (`+ B`).\n",
    "    *   The main `forward_propagation` function orchestrates this for the entire network, returning the final prediction (`a2`, also called `y_hat`) and the outputs of the hidden layer (`a1`).\n",
    "    *   `a1` (the output of the hidden layer) is needed later for derivative calculations.\n",
    "\n",
    "*   **Step 2: Calculate the Loss**\n",
    "    *   After getting the prediction (`y_hat`), the **Mean Squared Error (MSE)** loss function is used to quantify the difference between the prediction and the actual LPA (`y`) for that student.\n",
    "    *   Loss formula: `L = (y - y_hat)^2`.\n",
    "\n",
    "*   **Step 3: Update Weights and Biases (Backpropagation)**\n",
    "    *   This is the \"backward\" step where the network's parameters are adjusted to reduce the calculated loss.\n",
    "    *   A custom function `update_parameters` performs these adjustments.\n",
    "    *   It uses the **gradient descent formula**:\n",
    "        `Parameter_new = Parameter_old - (Learning_Rate * Partial_Derivative_of_Loss_with_Respect_to_Parameter)`.\n",
    "    *   The \"Learning Rate\" (e.g., 0.001) controls the step size of the updates.\n",
    "    *   All **nine partial derivatives** (of the loss with respect to each weight and bias, which were conceptually discussed in Part 1) are calculated and applied. For example, a derivative might involve terms like `(y - y_hat)`, `a1` (previous layer's output), and `x_i` (input).\n",
    "    *   The `update_parameters` function directly incorporates these derivative formulas to update `w1`, `b1`, `w2`, and `b2`.\n",
    "    *   After each student, the parameters are slightly adjusted, and this change can be observed.\n",
    "\n",
    "**2.4. Monitoring Progress**\n",
    "*   After each epoch (all students processed once), the **average loss** across all students is calculated and displayed.\n",
    "*   As training progresses over multiple epochs, the average loss is expected to **decrease**, indicating that the neural network is learning and making better predictions.\n",
    "*   The final values of the weights and biases after all epochs are printed, showing how they have converged from their initial values.\n",
    "\n",
    "**2.5. Comparison with Keras**\n",
    "*   The same regression problem is also implemented using the Keras library for comparison.\n",
    "*   To ensure a fair comparison, Keras's initial random weights are overridden to match the custom code's initial weights (e.g., 0.1 for weights, 0 for biases).\n",
    "*   The learning rate and loss function (MSE) are also set to match.\n",
    "*   The results show that Keras achieves a **similar reduction in loss** and similar final parameter values, validating the correctness of the custom backpropagation implementation.\n",
    "\n",
    "**3. Backpropagation for a Classification Problem**\n",
    "\n",
    "**3.1. Goal and Dataset**\n",
    "*   The objective is to predict if a student will be placed (1) or not (0) based on their CGPA and Profile Score.\n",
    "*   **New Dataset:** Features include CGPA, Profile Score, and a binary target \"Placement\" (0 or 1).\n",
    "*   **Neural Network Architecture:** Remains the same (2 input, 2 hidden, 1 output).\n",
    "\n",
    "**3.2. Key Changes for Classification**\n",
    "The backpropagation algorithm remains structurally similar, but two crucial components change:\n",
    "*   **Activation Function:** Instead of linear activation, a **Sigmoid activation function** is used in all three nodes (both hidden layer nodes and the output layer node).\n",
    "    *   In the `linear_forward` and `forward_propagation` functions, the dot product result (`Z`) is now passed through the Sigmoid function to get the activation (`A`).\n",
    "*   **Loss Function:** Instead of Mean Squared Error, **Binary Cross-Entropy** is used, which is appropriate for binary classification problems.\n",
    "    *   Loss formula: `L = -y * log(y_hat) - (1 - y) * log(1 - y_hat)`.\n",
    "\n",
    "**3.3. Recalculating Derivatives for Classification**\n",
    "Due to the new activation and loss functions, all nine partial derivatives of the loss with respect to each weight and bias must be recalculated. The **Chain Rule of Differentiation** is extensively used.\n",
    "\n",
    "*   **Derivatives for Output Layer (W2, B2):**\n",
    "    *   The term `(∂L/∂y_hat) * (∂y_hat/∂Z_final)` simplifies to `(y_hat - y)`.\n",
    "    *   This is a significant simplification compared to what would be obtained with MSE and linear activation.\n",
    "    *   Then, `∂L/∂W_211 = (y_hat - y) * O_11` (where `O_11` is the output of the first hidden node).\n",
    "    *   `∂L/∂W_212 = (y_hat - y) * O_12` (where `O_12` is the output of the second hidden node).\n",
    "    *   `∂L/∂B_2 = (y_hat - y) * 1`.\n",
    "\n",
    "*   **Derivatives for Hidden Layer (W1, B1):** These are more complex due to the nested dependencies.\n",
    "    *   For `∂L/∂W_111`, the chain rule involves: `(∂L/∂y_hat) * (∂y_hat/∂Z_final) * (∂Z_final/∂O_11) * (∂O_11/∂Z_previous) * (∂Z_previous/∂W_111)`.\n",
    "    *   `∂L/∂y_hat * ∂y_hat/∂Z_final` is again `(y_hat - y)`.\n",
    "    *   `∂Z_final/∂O_11` is `W_211` (the weight connecting `O_11` to the output node).\n",
    "    *   `∂O_11/∂Z_previous` is the derivative of the Sigmoid function, which is `O_11 * (1 - O_11)`.\n",
    "    *   `∂Z_previous/∂W_111` is `X_i1` (the first input feature for the current student).\n",
    "    *   Combining these terms gives the full derivative for `W_111`: `(y_hat - y) * W_211 * O_11 * (1 - O_11) * X_i1`.\n",
    "    *   Similar calculations are performed for `W_112`, `B_11`, `W_121`, `W_122`, and `B_12`, each following the chain rule to link the loss back to the specific parameter.\n",
    "\n",
    "**3.4. Implementation and Observations**\n",
    "*   The `update_parameters` function is again modified to incorporate these new derivative formulas specific to Sigmoid activation and Binary Cross-Entropy loss.\n",
    "*   The code is run with the classification dataset.\n",
    "*   **Observation:** Both the custom backpropagation code and the Keras implementation for this specific (small) classification dataset **struggle to converge** (loss does not decrease significantly over epochs).\n",
    "*   However, since both implementations yield similar loss values, it indicates that the custom code is correctly implementing the algorithm, even if the dataset or model hyperparameters prevent strong convergence.\n",
    "\n",
    "**4. Conclusion**\n",
    "*   This video demonstrated the **practical implementation (\"The How\")** of backpropagation for both regression and classification problems by writing custom code.\n",
    "*   It showed how to initialise parameters, perform forward propagation, calculate loss, and update weights and biases using gradient descent with the appropriate derivative calculations (including using the chain rule for both linear/MSE and sigmoid/binary cross-entropy scenarios).\n",
    "*   Comparison with Keras confirmed the correctness of the custom implementations.\n",
    "*   The importance of **practice** (running the code and performing manual calculations) is emphasised for a deeper understanding of backpropagation.\n",
    "*   The next video in the series will cover \"The Why\" of backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78e4ea-2c0b-457a-967e-034ba1791c66",
   "metadata": {},
   "source": [
    "### Backpropagation Part 3: The Why (Intuition Behind the Algorithm)\n",
    "\n",
    "This video focuses on understanding the **intuition behind the Backpropagation algorithm** and **why it works correctly** to yield accurate results, building on previous discussions of \"what\" and \"how\" Backpropagation operates.\n",
    "\n",
    "#### 1. Backpropagation Algorithm Overview\n",
    "The Backpropagation algorithm involves the following steps:\n",
    "*   **Decide on a number of epochs:** This determines how many times you want to iterate over your data.\n",
    "*   **Loop through each epoch:**\n",
    "    *   For each row in your dataset, perform the following:\n",
    "        *   **Randomly choose a data point.**\n",
    "        *   **Calculate a prediction (y_hat)** using forward propagation.\n",
    "        *   **Calculate the loss** between the prediction (y_hat) and the actual target (y). Common loss functions include Mean Squared Error (MSE) for regression and Binary Cross Entropy for classification.\n",
    "        *   **Update all weights and biases** using a specific rule.\n",
    "\n",
    "The core of Backpropagation, and the main focus of this video, is to understand **why and how updating weights and biases gradually leads to correct gradients and optimal values**.\n",
    "\n",
    "#### 2. Concept of the Loss Function as a Function of All Parameters\n",
    "*   The **loss function** (e.g., L = (y - y_hat)²) is a **mathematical function**.\n",
    "*   While `y` (the target value from your data) is constant, `y_hat` is the output of the neural network.\n",
    "*   **`y_hat` itself is a complex function** of all the weights (w) and biases (b) in the neural network, as it is derived through calculations involving these parameters at each node and layer.\n",
    "    *   For example, in a simple neural network, `y_hat` can be expressed as a complex equation involving all weights (`w11`, `w12`, `w21`, etc.) and biases (`b11`, `b12`, `b21`, etc.).\n",
    "*   Therefore, the **loss function is a function of all the trainable parameters** (weights and biases) in the neural network. If any of these parameters are changed, the loss will change.\n",
    "*   The goal is to **tune these parameters** (like turning knobs on a box) in such a way that the **loss function is minimised**.\n",
    "\n",
    "#### 3. Concept of Gradients\n",
    "*   **Gradient is a fancy word for derivative**.\n",
    "*   **Derivative** is used when a function depends on **only one parameter** (e.g., `y = f(x)`, you calculate `dy/dx`).\n",
    "*   **Gradient** is used when a function depends on **more than one parameter** (e.g., `z = f(x, y)`, you calculate partial derivatives `∂z/∂x` and `∂z/∂y`).\n",
    "*   The loss function in a neural network is a **complex mathematical function dependent on many parameters** (weights and biases).\n",
    "*   When we \"differentiate the loss function\" with respect to all its parameters, we are **calculating gradients** (specifically, partial derivatives for each weight and bias).\n",
    "*   **Geometric intuition:** For a one-dimensional function, the derivative represents the **slope** at a point. For multi-dimensional functions (like our loss function in a 9-dimensional space, for example), calculating gradients means calculating **9 different slopes** with respect to each dimension (parameter).\n",
    "\n",
    "#### 4. Intuition of Derivatives and Rate of Change\n",
    "*   The derivative (or gradient) represents the **rate of change** of one quantity with respect to another.\n",
    "*   `dy/dx` tells us **how much `y` changes when `x` changes by one unit**, considering both **magnitude** and **sign**.\n",
    "    *   If `dy/dx = 2`, it means a one-unit positive change in `x` causes a two-unit positive change in `y`.\n",
    "    *   If `dy/dx = -2`, it means a one-unit positive change in `x` causes a two-unit negative change in `y`.\n",
    "*   **Derivative at a point:** This tells us the rate of change at a specific value of `x` (e.g., `dy/dx` at `x=5` is `11`).\n",
    "*   In Backpropagation, when we calculate `∂L/∂w`, we are determining **how a one-unit change in a specific weight (`w`) affects the loss (`L`)**, both in terms of magnitude and whether it increases or decreases the loss.\n",
    "\n",
    "#### 5. Concept of Finding a Minimum\n",
    "*   To find the **minimum of a function**, we typically **calculate its derivative and set it to zero** (e.g., for `y = x²`, `dy/dx = 2x`, setting `2x = 0` gives `x = 0`, which is the minimum).\n",
    "*   For functions with **multiple variables** (like `z = x² + y²`), we calculate **partial derivatives** with respect to each variable and set them all to zero (e.g., `∂z/∂x = 2x = 0` and `∂z/∂y = 2y = 0`, leading to `x=0, y=0` for the minimum).\n",
    "*   Our loss function depends on **nine or more parameters** (weights and biases). To minimise this loss, we need to find the values of all these parameters for which **all their respective partial derivatives (gradients) are zero**. This means finding the minimum in a multi-dimensional space.\n",
    "\n",
    "#### 6. Understanding the Weight Update Rule\n",
    "The core update rule in Backpropagation is:\n",
    "**`w_new = w_old - (learning_rate * ∂L/∂w)`**\n",
    "\n",
    "Let's understand the **`w_old - ∂L/∂w`** part first, assuming `learning_rate = 1`:\n",
    "\n",
    "*   **Case 1: `∂L/∂w` is Positive**\n",
    "    *   If `∂L/∂w` is positive, it means **increasing `w` would increase the loss `L`**.\n",
    "    *   Since our goal is to **decrease `L`**, we must **decrease `w`**.\n",
    "    *   Subtracting a positive `∂L/∂w` from `w_old` achieves this decrease in `w_new` (e.g., `5 - (+value)` makes `w_new` smaller than `5`).\n",
    "*   **Case 2: `∂L/∂w` is Negative**\n",
    "    *   If `∂L/∂w` is negative, it means **increasing `w` would decrease the loss `L`**. (Or, conversely, decreasing `w` would increase `L`).\n",
    "    *   Since our goal is to **decrease `L`**, we should **increase `w`**.\n",
    "    *   Subtracting a negative `∂L/∂w` from `w_old` effectively **adds** to `w_old`, thus increasing `w_new` (e.g., `5 - (-value)` makes `w_new` larger than `5`).\n",
    "\n",
    "This \"smartly\" handles both scenarios: by **subtracting the gradient**, the algorithm always moves the weights in the direction that **reduces the loss**.\n",
    "\n",
    "*   **Graphical Intuition (Gradient Descent):**\n",
    "    *   Imagine the loss function as a 3D or higher-dimensional surface. Our goal is to find the lowest point.\n",
    "    *   When we calculate the slope (gradient) at our current position, if the slope is positive, we move in the negative direction (downhill). If the slope is negative, we still move in the negative direction of that slope (which means moving in the positive direction of the weight to get downhill).\n",
    "    *   Therefore, we always move in the **negative direction of the gradient** to descend towards the minimum.\n",
    "\n",
    "#### 7. The Concept of Learning Rate\n",
    "*   The **learning rate** (`η` or `α`) is a crucial hyperparameter that determines the **size of the steps** taken towards the minimum.\n",
    "*   It **smoothes the steps** and prevents overshooting.\n",
    "*   **Large Learning Rate:**\n",
    "    *   If the learning rate is too large (e.g., `0.5` or `1.0`), the steps taken are too big.\n",
    "    *   This can lead to **overshooting the minimum** or even **divergence** (bouncing out of the curve entirely and never finding the minimum).\n",
    "    *   Visualisation shows steps that jump across the minimum, failing to converge.\n",
    "*   **Small Learning Rate:**\n",
    "    *   If the learning rate is too small (e.g., `0.001`), the steps taken are very tiny.\n",
    "    *   This results in **very slow convergence**, meaning the algorithm takes a long time to train and reach the minimum.\n",
    "    *   Visualisation shows many small, slow steps to reach the minimum.\n",
    "*   **Optimal Learning Rate:** A good learning rate allows for **smooth, efficient convergence** to the minimum. It is often a small value like `0.1` or `0.01`.\n",
    "*   Finding the right learning rate is **very important** for successful model training.\n",
    "\n",
    "#### 8. When to Stop Backpropagation (Epochs and Convergence)\n",
    "*   The goal is to stop updating weights when the **loss function has been minimised**.\n",
    "*   **Theoretical approach (Convergence):** Training should stop when **convergence occurs**. This means that the new weight value (`w_new`) is very close to the old weight value (`w_old`), implying that the entire `(learning_rate * ∂L/∂w)` term is approaching zero. This indicates that the **slope at the current point is close to zero**, meaning a minimum has been reached.\n",
    "*   **Practical approach (Epochs):** In practice, developers often set a **fixed number of epochs** (e.g., 100 or 1000) for the outer loop. This is a heuristic assumption that convergence will likely occur within that number of iterations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c623129d-4d7a-4eb5-8df5-b7e1d9efac99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
