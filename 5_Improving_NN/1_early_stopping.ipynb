{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56279f35-3670-40f4-9bd0-e499a21da154",
   "metadata": {},
   "source": [
    "# Early Stopping in Neural Networks\n",
    "\n",
    "**1. Introduction to Early Stopping**\n",
    "\n",
    "*   **Purpose:** Early Stopping is a mechanism used to improve neural network training by preventing overfitting and determining the optimal number of training epochs.\n",
    "*   **Context:** When training a neural network, you must specify the number of epochs – how many times the model iterates over the same data. Deciding the correct number of epochs (e.g., 100 vs. 1000) is crucial.\n",
    "\n",
    "**2. The Problem: Overfitting**\n",
    "\n",
    "*   **Definition:** Overfitting occurs when a model is trained for too many epochs, causing it to perform exceptionally well on the training data but poorly on new, unseen data.\n",
    "*   **Identification:** This can be observed by monitoring both training loss and validation loss.\n",
    "    *   Initially, both training and validation loss decrease.\n",
    "    *   At a certain point, the validation loss (loss on the test/unseen data) starts to *increase*, while the training loss may continue to decrease. This divergence signifies overfitting.\n",
    "    *   The \"gap\" between training and validation loss widens as overfitting progresses.\n",
    "*   **Example from Source:** An example demonstrated training a model for 3500 epochs. The validation loss initially reduced but then began to increase around 360-380 epochs, indicating overfitting despite the training loss continuing to decrease. The ideal stopping point would have been around 360-380 epochs.\n",
    "\n",
    "**3. What is Early Stopping?**\n",
    "\n",
    "*   **Mechanism:** Early Stopping is a Keras mechanism that automatically detects when further training will not provide benefit, but rather cause harm (i.e., overfitting or increasing loss), and stops the model's training at that point.\n",
    "*   **How it Works:** It monitors a specified metric (e.g., validation loss) during training and halts the process if the metric no longer improves for a certain number of epochs.\n",
    "*   **Benefit:** It allows the model to stop training at the point where it achieves the best generalisation performance, without having to manually guess the number of epochs.\n",
    "\n",
    "**4. Implementing Early Stopping in Keras**\n",
    "\n",
    "*   **Keras Callbacks:** Early Stopping is implemented using the \"callback\" feature in Keras. Callbacks are functions that can be applied at certain stages of the training process (e.g., after each epoch).\n",
    "*   **Steps:**\n",
    "    1.  **Define Model and Compile:** As usual, set up your Keras model and compile it (no changes required here for Early Stopping).\n",
    "    2.  **Create EarlyStopping Object:** Instantiate an `EarlyStopping` object from Keras. This object is a class constructor that takes several parameters.\n",
    "    3.  **Add to Callbacks List:** Store the `EarlyStopping` object in a list, typically named `callbacks`.\n",
    "    4.  **Pass to `model.fit()`:** Provide this `callbacks` list to the `callbacks` parameter in the `model.fit()` method.\n",
    "\n",
    "*   **Demonstration:** When implemented, the model that previously trained for 3500 epochs and overfit, stopped automatically at 327 epochs, confirming that this was the optimal point to prevent overfitting. The resulting model's plot showed the validation loss diverging from the training loss at this point, but the training was stopped before significant overfitting occurred.\n",
    "\n",
    "**5. Key Parameters of the `EarlyStopping` Callback**\n",
    "\n",
    "These parameters allow for flexibility in the Early Stopping mechanism:\n",
    "\n",
    "*   **`monitor`**:\n",
    "    *   **Purpose:** Specifies the quantity to be monitored for improvement.\n",
    "    *   **Common Use:** Typically set to `'val_loss'` (validation loss) as it directly reflects performance on unseen data. It can also be `'val_accuracy'` (validation accuracy).\n",
    "    *   **Logic:** If monitoring loss, training stops when loss stops decreasing. If monitoring accuracy, training stops when accuracy stops increasing.\n",
    "*   **`min_delta`**:\n",
    "    *   **Purpose:** The minimum change in the monitored quantity to qualify as an \"improvement\".\n",
    "    *   **Example:** If `min_delta` is 0.001, an improvement of 0.0005 would not be considered significant enough, and the model would continue to monitor for a larger change.\n",
    "*   **`patience`**:\n",
    "    *   **Purpose:** The number of epochs with no improvement after which training will be stopped.\n",
    "    *   **Mechanism:** It acts as a buffer. Even if an epoch shows no improvement, training won't stop immediately. The model waits for `patience` number of epochs. If no improvement is observed during this period, training stops.\n",
    "    *   **Example:** If `patience=3`, the model will wait for 3 consecutive epochs with no improvement before stopping.\n",
    "*   **`verbose`**:\n",
    "    *   **Purpose:** Controls the verbosity of the output messages.\n",
    "    *   **Values:** `0` means no messages are printed, `1` means messages (like \"Early stopping\") are printed.\n",
    "*   **`mode`**:\n",
    "    *   **Purpose:** Determines the direction of improvement.\n",
    "    *   **Values:**\n",
    "        *   `'auto'` (default): Keras intelligently infers whether to look for a minimum or maximum based on the `monitor` quantity (e.g., a minimum for loss, a maximum for accuracy). This is generally recommended.\n",
    "        *   `'min'`: Training stops when the monitored quantity has stopped *decreasing* (e.g., for loss).\n",
    "        *   `'max'`: Training stops when the monitored quantity has stopped *increasing* (e.g., for accuracy).\n",
    "*   **`baseline`**:\n",
    "    *   **Purpose:** A baseline value for the monitored quantity. Training will stop if the model doesn't show improvement over this baseline.\n",
    "    *   **Usage:** Requires a strong understanding of your data and a specific target for performance.\n",
    "*   **`restore_best_weights`**:\n",
    "    *   **Purpose:** Whether to restore model weights from the epoch with the best value of the monitored quantity.\n",
    "    *   **Values:**\n",
    "        *   `True`: The model's weights will revert to those from the epoch where the `monitor` quantity was at its optimal value (e.g., lowest validation loss).\n",
    "        *   `False` (default): The model will retain the weights from the *last* epoch it trained, which might not be the absolute best.\n",
    "\n",
    "**6. Conclusion**\n",
    "\n",
    "*   Early Stopping is a powerful and practical feature in deep learning.\n",
    "*   It simplifies the training process by automatically deciding the optimal number of epochs, saving time, and preventing the negative effects of overfitting.\n",
    "*   Experimenting with its parameters is encouraged to develop an intuition for how it works and to achieve the best results for a specific model and dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e05874-4be8-40fc-a504-6288e68fa35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8ff9e5-9c69-4767-82c9-9f5513753798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02cf0b0-1936-480a-bd05-b0b7fd56150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/pankaj-2708/Machine-Learning/refs/heads/main/Datasets/placement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c377aa8c-9287-4da7-a1af-8b40fd480855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>placement_exam_marks</th>\n",
       "      <th>placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.19</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.46</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.54</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.23</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  placement_exam_marks  placed\n",
       "0  7.19                  26.0       1\n",
       "1  7.46                  38.0       1\n",
       "2  7.54                  40.0       1\n",
       "3  6.42                   8.0       1\n",
       "4  7.23                  17.0       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "486eefeb-951b-4423-b790-1903ee8fc7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\panka\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(10,input_dim=2,activation='sigmoid'))\n",
    "model.add(Dense(6,activation='sigmoid'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c471d124-234f-4986-ad25-5bb372492fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X=df.drop(columns='placed')\n",
    "y=df['placed']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "std=StandardScaler()\n",
    "X_train=std.fit_transform(X_train)\n",
    "X_test=std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c6be08a-d9aa-4322-abd7-8360c2fef85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback=EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "181e0a48-193f-4877-9cb8-4247b004b236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.4975 - loss: 0.6960 - val_accuracy: 0.5500 - val_loss: 0.6894\n",
      "Epoch 2/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5000 - loss: 0.6947 - val_accuracy: 0.5400 - val_loss: 0.6901\n",
      "Epoch 3/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4925 - loss: 0.6945 - val_accuracy: 0.5400 - val_loss: 0.6926\n",
      "Epoch 4/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4512 - loss: 0.6945 - val_accuracy: 0.4700 - val_loss: 0.6936\n",
      "Epoch 5/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4938 - loss: 0.6941 - val_accuracy: 0.5650 - val_loss: 0.6922\n",
      "Epoch 6/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4588 - loss: 0.6943 - val_accuracy: 0.4650 - val_loss: 0.6940\n",
      "Epoch 7/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4663 - loss: 0.6940 - val_accuracy: 0.5150 - val_loss: 0.6929\n",
      "Epoch 8/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4700 - loss: 0.6939 - val_accuracy: 0.4600 - val_loss: 0.6936\n",
      "Epoch 9/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4688 - loss: 0.6939 - val_accuracy: 0.4650 - val_loss: 0.6937\n",
      "Epoch 10/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4600 - loss: 0.6937 - val_accuracy: 0.4700 - val_loss: 0.6935\n",
      "Epoch 11/10000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4450 - loss: 0.6938 - val_accuracy: 0.4500 - val_loss: 0.6942\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e646f07f00>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10000,callbacks=callback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
