{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16beeffa-3c58-49e2-8b5c-213d4c6ebbcf",
   "metadata": {},
   "source": [
    "### **Optimizers in Deep Learning**\n",
    "\n",
    "This section of the Deep Learning course focuses on **Optimizers**, a crucial topic for improving neural network performance.\n",
    "\n",
    "**1. Context and Importance**\n",
    "*   Previous videos focused on improving neural network performance, specifically **speeding up training**.\n",
    "*   Training deep neural networks can be very time-consuming, especially with many hidden layers.\n",
    "*   Previous techniques to speed up training include:\n",
    "    *   Weight Initialisation\n",
    "    *   Batch Normalisation\n",
    "    *   Choice of Activation Function\n",
    "*   **Optimizers** are presented as the **fourth and arguably most important technique** for increasing the training speed of neural networks.\n",
    "*   The goal is to understand how optimizers increase neural network training speed.\n",
    "\n",
    "**2. The Role of an Optimizer in a Neural Network**\n",
    "*   A neural network's primary function is to **find optimal values for its weights and biases** (parameters).\n",
    "*   Example: A simple neural network with 9 parameters (weights and biases).\n",
    "*   When data is fed into the network, it produces a prediction.\n",
    "*   The objective is to find parameter values such that the **predictions are very close to the actual (real) results**.\n",
    "*   This is achieved by **minimising the \"loss function\"** (or \"cost function\"), which represents the difference between the predicted output (Y-hat) and the real output (Y).\n",
    "*   **Process:**\n",
    "    1.  Start with **random initial values** for weights and biases.\n",
    "    2.  Gradually **improve these values** to reach the \"correct\" or \"optimum\" values.\n",
    "*   **Graphical Representation (Loss Surface):**\n",
    "    *   The loss function can be visualised as a multi-dimensional graph (e.g., 3D if there are two weights and one loss axis).\n",
    "    *   The goal is to navigate this loss surface from a starting random point to the **global minimum**, where the loss is lowest.\n",
    "    *   The weights corresponding to this global minimum are the optimum parameters for the neural network.\n",
    "    *   **An optimizer is required to perform this task** of finding the minimum loss and corresponding optimum weight values.\n",
    "\n",
    "**3. Gradient Descent as an Optimizer**\n",
    "*   The primary optimizer used in deep learning is **Gradient Descent**.\n",
    "*   **Update Rule:** Gradient Descent uses a simple rule to update weights iteratively:\n",
    "    *   `new_weight = old_weight - learning_rate * gradient_of_loss_wrt_weight`\n",
    "    *   The **learning rate** determines the size of the steps taken.\n",
    "    *   Gradient Descent is designed to take **larger jumps when far from the minimum** and **smaller jumps as it approaches the minimum**.\n",
    "*   **Types of Gradient Descent (already covered in previous videos, but briefly reviewed):**\n",
    "    *   **Batch Gradient Descent (BGD):**\n",
    "        *   Updates weights **once per epoch** (one full pass over the entire dataset).\n",
    "        *   Calculates predictions and loss over the **entire dataset** (e.g., 5000 rows) before updating weights.\n",
    "        *   Results in fewer weight updates per epoch.\n",
    "    *   **Stochastic Gradient Descent (SGD):**\n",
    "        *   Updates weights **after seeing each individual data point**.\n",
    "        *   If there are 5000 data points, weights are updated 5000 times per epoch.\n",
    "        *   Results in many weight updates, making it computationally intensive but potentially faster at escaping local minima.\n",
    "    *   **Mini-batch Gradient Descent (MBGD):**\n",
    "        *   A compromise between BGD and SGD.\n",
    "        *   Updates weights after processing a **small batch of data points** (e.g., batch size of 100).\n",
    "        *   The dataset is divided into mini-batches, and weights are updated after each mini-batch.\n",
    "*   A clear understanding of these Gradient Descent types is crucial for grasping new optimizers.\n",
    "\n",
    "**4. Problems/Challenges with Conventional Gradient Descent**\n",
    "Despite its utility, conventional Gradient Descent (BGD, SGD, MBGD) faces several challenges:\n",
    "\n",
    "*   **Challenge 1: Difficulty in Setting the Learning Rate**\n",
    "    *   The learning rate is a **critical hyperparameter**.\n",
    "    *   **If the learning rate is too small:**\n",
    "        *   **Convergence is extremely slow**, as steps are tiny.\n",
    "        *   May take too long to reach the minimum, or might not reach it at all.\n",
    "    *   **If the learning rate is too large:**\n",
    "        *   The optimizer **overshoots the minimum**, leading to oscillations or even divergence.\n",
    "        *   Training can become **unstable**, moving further away from the minimum.\n",
    "    *   Finding the optimal learning rate is a **difficult and dataset-dependent task**.\n",
    "\n",
    "*   **Challenge 2: Limitations of Learning Rate Scheduling**\n",
    "    *   **Learning rate scheduling** was introduced to mitigate the problem of a fixed learning rate.\n",
    "    *   It involves **automatically changing or reducing the learning rate** based on a predefined schedule or when certain objectives are met.\n",
    "    *   **Problem:** The schedule or thresholds must be **predefined before training**.\n",
    "    *   This means the scheduling is **not adaptive to the specific dataset** during training.\n",
    "    *   A schedule that works well for one dataset might not perform optimally for another.\n",
    "\n",
    "*   **Challenge 3: Using a Single Learning Rate for Multiple Parameters**\n",
    "    *   In a neural network, there are often **many weight and bias parameters** (e.g., 9 parameters in the example).\n",
    "    *   This implies a high-dimensional loss surface.\n",
    "    *   Conventional Gradient Descent applies a **single, uniform learning rate** across **all dimensions/parameters**.\n",
    "    *   **Restriction:** It **cannot have separate learning rates** for different weight parameters.\n",
    "    *   This is problematic because different directions on the loss surface might require different step sizes (e.g., faster movement in one direction, slower in another) for efficient convergence.\n",
    "\n",
    "*   **Challenge 4: Getting Stuck in Local Minima**\n",
    "    *   The loss functions of complex neural networks often have **multiple local minima**, in addition to the global minimum.\n",
    "    *   The ultimate goal is to reach the **global minimum** (the point of lowest possible loss).\n",
    "    *   Conventional Gradient Descent algorithms have a **high probability of getting trapped in a local minimum**.\n",
    "    *   If stuck in a local minimum, the algorithm converges to a **sub-optimal solution**.\n",
    "    *   Stochastic Gradient Descent (SGD) has a *slight* potential to escape local minima due to its noisy updates.\n",
    "\n",
    "*   **Challenge 5: Encountering Saddle Points**\n",
    "    *   A **saddle point** is a region on the loss surface where the slope is positive in one direction but negative in another.\n",
    "    *   This creates a large, flat region where the **slope (gradient) is close to zero** in all directions.\n",
    "    *   If the gradient is zero, the weight update rule will result in **no change to the weights** (`new_weight = old_weight`).\n",
    "    *   This causes the algorithm to get stuck, even though it's not an optimal solution.\n",
    "    *   Conventional Gradient Descent algorithms **cannot effectively navigate or escape saddle points**.\n",
    "\n",
    "**5. The Need for New Optimizers**\n",
    "*   These challenges (slow training, sub-optimal results, difficulty with hyperparameter tuning) highlight the limitations of conventional Gradient Descent.\n",
    "*   Therefore, **new optimizers** have been developed to address these problems and improve training efficiency and effectiveness.\n",
    "*   These new optimizers are generally **improvements or modifications to the core Gradient Descent algorithm**, rather than entirely new concepts.\n",
    "*   **Upcoming Optimizers to be covered:**\n",
    "    *   Momentum\n",
    "    *   Adagrad\n",
    "    *   RMSprop\n",
    "    *   Adam (most widely used)\n",
    "*   To understand these new optimizers, the concept of **Exponentially Weighted Moving Average** will be covered next, as it is foundational to many of them.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d60772-16d0-4bad-b3b1-640e2a818f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
