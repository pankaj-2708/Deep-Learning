{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274d48d6-2210-4502-9e39-a5ae320ea4a9",
   "metadata": {},
   "source": [
    "### **Exponentially Weighted Moving Average (EWMA)**\n",
    "\n",
    "This section introduces the concept of **Exponentially Weighted Moving Average (EWMA)**, a crucial technique for understanding advanced optimizers in deep learning.\n",
    "\n",
    "**1. Introduction to EWMA**\n",
    "*   EWMA is an important concept that needs to be understood *before* delving into specific optimizers.\n",
    "*   It is a technique used to **find trends in time-series based data**.\n",
    "*   Examples of time-series data include daily stock fluctuations or daily temperature records for a city.\n",
    "*   The goal is to extract the underlying **pattern or trend** from such data.\n",
    "*   Visually, the EWMA often appears as a smoother curve that \"blends\" with the data, unlike a simple average which might appear as a straight line.\n",
    "\n",
    "**2. Applications of EWMA**\n",
    "*   **Time-series forecasting**.\n",
    "*   **Company financial forecasting**.\n",
    "*   **Signal processing** in science.\n",
    "*   **Deep Learning:** It is used while building some **optimizers**. Specifically, it is foundational for optimization techniques like **Momentum**.\n",
    "\n",
    "**3. Key Principles of EWMA Calculation**\n",
    "EWMA adheres to two main principles when calculating the average:\n",
    "1.  **Later points are given more weight:** When calculating EWMA, **more recent data points are weighted more heavily** compared to older data points. For instance, a data point from Day 5 will have more weight than a data point from Day 3.\n",
    "2.  **Weight decreases over time:** The weight of any given data point **reduces as time passes**.\n",
    "\n",
    "**4. Mathematical Formula of EWMA**\n",
    "The formula for Exponentially Weighted Moving Average at a particular time `t` (`Vt`) is:\n",
    "`Vt = β * Vt-1 + (1 - β) * Tt`\n",
    "\n",
    "Where:\n",
    "*   `Vt`: The EWMA at time `t`.\n",
    "*   `β (Beta)`: A constant value between 0 and 1 (0 < β < 1).\n",
    "*   `Vt-1`: The EWMA from the previous time step (`t-1`).\n",
    "*   `Tt`: The actual data point (e.g., temperature) at time `t`.\n",
    "\n",
    "**5. Step-by-Step Calculation Example**\n",
    "Let's assume `V0 = 0` (though some sources might directly set `V0 = T0`) and a common `β` value of **0.9** (often used in deep learning):\n",
    "\n",
    "*   **V0**: Can be set to 0 or equal to T0 (the first data point). Let's assume V0 = 0 for this example.\n",
    "*   **V1**: `V1 = β * V0 + (1 - β) * T1`\n",
    "    *   If `β = 0.9` and `T1 = 30` (from example data):\n",
    "    *   `V1 = 0.9 * 0 + (1 - 0.9) * 30 = 0.1 * 30 = 3`.\n",
    "*   **V2**: `V2 = β * V1 + (1 - β) * T2`\n",
    "    *   If `β = 0.9`, `V1 = 3`, and `T2 = 17` (from example data):\n",
    "    *   `V2 = 0.9 * 3 + 0.1 * 17 = 2.7 + 1.7 = 4.4`.\n",
    "*   This process continues for all subsequent data points (`V3, V4`, etc.), connecting the calculated `Vt` values to form the EWMA graph.\n",
    "\n",
    "**6. Impact of the `β` (Beta) Parameter**\n",
    "The value of `β` significantly affects the behavior and smoothness of the EWMA curve:\n",
    "\n",
    "*   **Intuition for `β`:** EWMA can be seen as an average of approximately `1 / (1 - β)` previous days' data.\n",
    "    *   If `β = 0.9`: It acts like an average of `1 / (1 - 0.9) = 1 / 0.1 = 10` days.\n",
    "    *   If `β = 0.5`: It acts like an average of `1 / (1 - 0.5) = 1 / 0.5 = 2` days.\n",
    "*   **High `β` value (e.g., 0.98):**\n",
    "    *   Means you are giving **more weight to older, past points** (`Vt-1` is multiplied by a larger `β`).\n",
    "    *   Results in a **smoother graph** that is less reactive to current fluctuations, as it incorporates more historical data. This personifies as a \"stable\" individual.\n",
    "*   **Low `β` value (e.g., 0.1 or 0.5):**\n",
    "    *   Means you are giving **more weight to current points** (`Tt` is multiplied by a larger `1 - β`).\n",
    "    *   Results in a **\"moody\" or spiky graph** that closely follows the current data, making it less smooth and more oscillatory. This personifies as a \"moody\" individual.\n",
    "*   **Sweet Spot for Deep Learning:** A common `β` value used in optimization algorithms in deep learning is **0.9**.\n",
    "\n",
    "**7. Mathematical Proof of Weighting**\n",
    "The formula `Vt = β * Vt-1 + (1 - β) * Tt` inherently gives more weight to recent data and less to older data.\n",
    "By repeatedly substituting `Vt-1`, `Vt-2`, etc., into the formula, we can expand `Vt` in terms of current and past data points (`Tt`, `Tt-1`, `Tt-2`, ...):\n",
    "*   `V1 = (1 - β)T1` (assuming V0=0)\n",
    "*   `V2 = β(1 - β)T1 + (1 - β)T2`\n",
    "*   `V3 = β²(1 - β)T1 + β(1 - β)T2 + (1 - β)T3`\n",
    "*   `V4 = β³(1 - β)T1 + β²(1 - β)T2 + β(1 - β)T3 + (1 - β)T4`\n",
    "\n",
    "Notice the coefficients for `T1`, `T2`, `T3`, `T4`:\n",
    "*   `T1` (oldest) is multiplied by `β³(1 - β)`\n",
    "*   `T2` is multiplied by `β²(1 - β)`\n",
    "*   `T3` is multiplied by `β(1 - β)`\n",
    "*   `T4` (most recent) is multiplied by `(1 - β)`\n",
    "\n",
    "Since `β` is between 0 and 1, `β³ < β² < β`. This mathematically demonstrates that **older data points (`T1`) are multiplied by smaller coefficients (closer to zero) compared to newer data points (`T4`), confirming that newer points receive higher weights**.\n",
    "\n",
    "**8. EWMA in Python (Pandas)**\n",
    "*   The `pandas` library in Python provides an `ewm()` function to calculate EWMA.\n",
    "*   It requires a parameter called `alpha`.\n",
    "*   **`alpha` is equivalent to `(1 - β)`**. So, if `α = 0.1`, then `β = 0.9`.\n",
    "*   **Syntax:** `dataframe_column.ewm(alpha=alpha_value).mean()`.\n",
    "*   This function calculates the EWMA for each row/data point, which can then be merged back into the original DataFrame and plotted.\n",
    "*   It is recommended to practice implementing EWMA from scratch without using the built-in function for better understanding.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c8c75fe-04bd-4a6f-9cf8-b3de796f5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=0.5\n",
    "def ewma(lst,i):\n",
    "    if i==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return beta*ewma(lst,i-1) + (1-beta)*lst[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d9b0298-b611-4070-b58a-25d73723a12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.03125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst=[1,2,3,4,5]\n",
    "ewma(lst,5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
