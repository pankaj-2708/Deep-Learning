{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4d2141-e49d-417f-ba99-0c4266c6c363",
   "metadata": {},
   "source": [
    "Technically, there are three primary types of RNNs: Many-to-One, One-to-Many, and Many-to-Many, though a fourth (One-to-One) is often discussed for context.\n",
    "\n",
    "---\n",
    "\n",
    "## Types of RNN Architectures\n",
    "\n",
    "### 1. Many-to-One RNN Architecture\n",
    "\n",
    "This architecture expects **sequential data as input** but produces a **single, non-sequential output**.\n",
    "\n",
    "| Feature | Description |\n",
    "| :--- | :--- |\n",
    "| **Input** | Sequence of data (e.g., words) |\n",
    "| **Output** | Scalar (e.g., 1 or 0, or a number between 1 and 5) |\n",
    "| **Architecture Flow** | Input is sent over several time steps. The main prediction/output is calculated only at the last time step. |\n",
    "| **Applications** | **Sentiment Analysis:** Processing text (a sequence) to determine overall sentiment (1 or 0). **Rating Prediction:** Reading movie reviews (textual sequence) to predict a star rating (1 to 5). |\n",
    "\n",
    "### 2. One-to-Many RNN Architecture\n",
    "\n",
    "This architecture is the opposite of Many-to-One. It receives **non-sequential data as input** and produces **sequential data as output**.\n",
    "\n",
    "| Feature | Description |\n",
    "| :--- | :--- |\n",
    "| **Input** | Single, non-sequential data (e.g., numbers, or an image) |\n",
    "| **Output** | Sequential data (e.g., a sequence of words) |\n",
    "| **Architecture Flow** | A single input is provided only once. Output is generated at every time step, and that output is fed back to the next time step. |\n",
    "| **Applications** | **Image Captioning:** Feeding an image (non-sequential data) to the network, which outputs a textual description (sequential data), such as \"A man is playing cricket\". **Music Generation:** Passing a single input to constantly generate music notes. |\n",
    "\n",
    "### 3. Many-to-Many RNN Architecture (Sequence-to-Sequence Models)\n",
    "\n",
    "The Many-to-Many type is considered one of the most interesting. In this architecture, both the **input and the output are sequential data**. Because of this characteristic, they are often referred to as **Sequence-to-Sequence (Seq2Seq) models**.\n",
    "\n",
    "This architecture is further divided into two types:\n",
    "\n",
    "#### A. Same Length Many-to-Many\n",
    "\n",
    "*   **Condition:** The size of the input sequence is the same as the size of the output sequence.\n",
    "*   **Architecture Flow:** The simple RNN module processes inputs, and an output is calculated at *every* time step. This output is then fed back to the next time step, along with the subsequent input.\n",
    "*   **Applications:**\n",
    "    *   **Part-of-Speech (PoS) Tagging:** For every word in an input sentence, a corresponding part-of-speech tag is the output.\n",
    "    *   **Named Entity Recognition (NER):** For every word, the network decides whether it represents an entity or not. This is commonly used in building chatbots.\n",
    "\n",
    "#### B. Variable Length Many-to-Many\n",
    "\n",
    "*   **Condition:** The length of the input sequence is *not* guaranteed to be the same as the length of the output sequence. This is necessary because different languages may represent the same sentence using a different number of words.\n",
    "*   **Architecture (Encoder-Decoder):** This model first requires the **entire input** to be processed before any output starts.\n",
    "    *   **Encoder:** The part where the entire input is provided sequentially.\n",
    "    *   **Decoder:** The part that starts generating the sequential output only after the last input has been sent.\n",
    "*   **Rationale:** Translation is a task where word-level translation is insufficient. To maintain grammatical meaning and context, the network must read the whole sentence (input) before starting the translation (output).\n",
    "*   **Application:** **Machine Translation** (e.g., translating \"Hey my name is Nitish\" into \"मेरा नाम नीतीश है\").\n",
    "\n",
    "### 4. One-to-One Architecture (Simple Neural Networks)\n",
    "\n",
    "Although included in the list of four types, **technically, this is not an RNN** because it lacks recurrence.\n",
    "\n",
    "| Feature | Description |\n",
    "| :--- | :--- |\n",
    "| **Input** | Non-sequential data |\n",
    "| **Output** | Non-sequential data |\n",
    "| **Architecture Flow** | A single input produces a single output. There is **no recurrence** and no involvement of time steps. |\n",
    "| **Classification** | This architecture corresponds to a **simple Neural Network (ANN or CNN)**. |\n",
    "| **Applications** | **Image Classification:** Input is an image, output is a classification (e.g., 1 or 0, indicating if the image contains a cat or not). |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl_py_9)",
   "language": "python",
   "name": "dl_py_9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
