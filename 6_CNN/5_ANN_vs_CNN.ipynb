{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cadf8c7-9169-4397-9879-3d8b5ff1edf4",
   "metadata": {},
   "source": [
    "## Lecture Notes: Comparing CNN vs. ANN\n",
    "\n",
    "### I. Introduction and Context\n",
    "\n",
    "*   This topic serves to continue the deep learning playlist.\n",
    "*   Understanding the similarities and differences between CNNs and ANNs is **crucial** for upcoming videos, particularly the explanation of backpropagation in CNNs.\n",
    "*   Drawing parallels between the two architectures can help in applying concepts learned from backpropagation in ANNs to CNNs.\n",
    "\n",
    "### II. Limitations of ANNs in Image Processing\n",
    "\n",
    "When using ANNs for image classification tasks, three major disadvantages arise:\n",
    "\n",
    "1.  **High Computational Cost:** Using ANNs for image tasks is computationally very costly.\n",
    "2.  **Overfitting:** There is an increased chance of overfitting.\n",
    "3.  **Loss of Important Features:** Features like the **spatial arrangement of pixels** are lost. This happens because the 2D image data must be flattened (brought to 1D) before being used as input by the ANN.\n",
    "\n",
    "### III. Processing Image Data: ANN vs. CNN\n",
    "\n",
    "The source uses a 28x28 image (like those in the MNIST dataset) to illustrate the processing difference.\n",
    "\n",
    "| Feature | Artificial Neural Network (ANN) | Convolutional Neural Network (CNN) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Input Format** | The 28x28 image is flattened (brought to 1D). | Uses the image in its original 2D form. |\n",
    "| **Input Size** | 784 inputs (28 multiplied by 28). | 28x28. |\n",
    "| **Architecture** | Input layer leads to hidden layers (fully connected layers). | **Convolution:** Filters are applied, creating a feature map. |\n",
    "| **Post-Processing** | Directly passes output to the softmax layer. | Feature map gets ReLU applied, followed by pooling (Max Pooling), then **flattening**. |\n",
    "| **Final Layer** | Softmax layer. | Flattened data goes to fully connected layers, then a Softmax layer. |\n",
    "\n",
    "### IV. Fundamental Similarities: The Core Principle\n",
    "\n",
    "Despite architectural differences, the basic working principle of CNN filters and ANN nodes is similar.\n",
    "\n",
    "*   **ANN Node Operation:** Inputs ($X_1, X_2$, etc.) are multiplied by their respective weights ($W_1, W_2$, etc.)—performing a **dot product**. A bias is added, and the result is passed through an **activation function** (e.g., ReLU).\n",
    "*   **CNN Filter Operation:** When a filter convolves, it performs the same mathematical operations on the input pixels within its scope. It calculates the **dot product** of the input pixel values and the filter’s internal values (which serve as the weights, $W_{i}$). It then adds the filter's bias and passes the result through an activation function (like ReLU).\n",
    "\n",
    "**Key Similarity Takeaway:** Both architectures execute the same core process: **dot product + bias + activation function**.\n",
    "\n",
    "**Difference in Application:**\n",
    "\n",
    "*   ANN nodes work on **all** inputs.\n",
    "*   CNN filters operate on an input **chunk** via the movement of a window, allowing it to capture 2D spatial arrangement.\n",
    "\n",
    "### V. Key Differences: Trainable Parameters and Computational Cost\n",
    "\n",
    "The primary difference lies in how the number of trainable parameters relates to the input image size, which explains the computational advantage of CNNs.\n",
    "\n",
    "#### CNN Parameters (Input Size Independent)\n",
    "\n",
    "*   **Computational Efficiency:** CNNs are computationally cost-effective.\n",
    "*   The number of trainable parameters in a CNN **does not depend on the size of the input image**. It only depends on:\n",
    "    1.  The size of the filter.\n",
    "    2.  The number of filters implemented.\n",
    "\n",
    "*   **Example Calculation:** For a 28x28x3 image using 50 filters of size 3x3x3:\n",
    "    *   Weights per filter: $3 \\times 3 \\times 3 = 27$.\n",
    "    *   Total weights: $27 \\times 50 = 1350$.\n",
    "    *   Total biases (one per filter): 50.\n",
    "    *   **Total Trainable Parameters: 1400**.\n",
    "    *   If the image size were dramatically increased (e.g., 1080x1080x3), the number of trainable parameters would **remain 1400**, because the filter size and number of filters are unchanged.\n",
    "\n",
    "#### ANN Parameters (Input Size Dependent)\n",
    "\n",
    "*   The number of weights in an ANN increases automatically as the input size increases.\n",
    "*   If the input size grows (e.g., 1080x1080x3), the required number of weights between the input and hidden layers (calculated as Input Units $\\times$ Hidden Units) **increases significantly** (potentially into the millions).\n",
    "*   This reliance on input size for weight calculation is why ANNs have increased computational cost and slower training times when dealing with large images.\n",
    "\n",
    "### VI. Conclusion\n",
    "\n",
    "The architectural design of CNNs allows them to capture the 2D spatial arrangement of pixels while ensuring the number of trainable weights remains fixed regardless of image input size, thereby mitigating the computational cost and overfitting issues faced by ANNs. This context sets the stage for training CNNs using the backpropagation algorithm.\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
