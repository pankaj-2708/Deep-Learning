


import tensorflow as tf
import numpy as np


# loading mnist data
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()


# train_labels test_images and test_labels are not required as gan is an unsupervised algoritham


train_images.shape


# reshaping them to no_of_images*hight*width*no_of_channels
train_images=train_images.reshape(train_images.shape[0],28,28,1).astype('float32')
# scaling from -1 to 1
train_images=(train_images-127.5)/127.5


train_images.shape


BUFFER_SIZE=60000
BATCH_SIZE=256


# SHUFFLING IMAGES
train_dataset=tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)


for element in train_dataset:
  print(element)
  break





from tensorflow.keras import layers

def make_generator_model():
  model=tf.keras.Sequential()

  # Using 7*7*128 units to project the 100-dimensional noise vector into a 7x7x128 feature map.
  # This will later be reshaped and upsampled through Conv2DTranspose layers to reach 28x28 â€”
  # matching the size of real images so the discriminator can process both real and generated images equally.
  model.add(layers.Dense(7*7*128, use_bias=False, input_shape=(100,)))
  model.add(layers.BatchNormalization())
  model.add(layers.LeakyReLU())

  # reshaping in to 7*7*128
  model.add(layers.Reshape((7,7,128)))

  model.add(layers.Conv2DTranspose(128,kernel_size=(5,5),strides=(1,1),padding='same',use_bias=False))
  model.add(layers.BatchNormalization())
  model.add(layers.LeakyReLU())


  model.add(layers.Conv2DTranspose(64,kernel_size=(5,5),strides=(2,2),padding='same',use_bias=False))
  model.add(layers.BatchNormalization())
  model.add(layers.LeakyReLU())

  # finally layer tanh is used because it will resize outputs to -1 to 1 so no normalisation will be required later
  model.add(layers.Conv2DTranspose(1,kernel_size=(5,5),strides=(2,2),padding='same',use_bias=False,activation='tanh'))

  return model





generator=make_generator_model()
generator.summary()





import matplotlib.pyplot as plt

noise=tf.random.normal([1,100])

# model(X, training=False) just performs a forward pass (i.e., forward propagation) through the network â€” it returns the output of the model for the given input X
# reason behind training=False
#Some layers behave differently depending on whether the model is training or not.
# Letâ€™s look at two main examples ðŸ‘‡

# ðŸ”¹ BatchNormalization

# During training:
# It normalizes the batch using current batch statistics (mean & variance)
# and updates running averages (moving mean/variance).

# During inference (training=False):
# It uses the stored moving averages â€” not the current batch â€”
# to give stable, deterministic results.

# ðŸ”¹ Dropout
# During training: randomly drops out neurons to prevent overfitting.
# During inference (training=False): disables dropout (keeps all neurons active).

generated_image=generator(noise,training=False)

plt.imshow(generated_image[0,:,:,0],cmap='gray')


generated_image.shape





def make_discrimanarator_model():
  model=tf.keras.Sequential()

  model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding='same',input_shape=[28,28,1]))
  model.add(layers.LeakyReLU())
  model.add(layers.Dropout(0.3))

  model.add(layers.Flatten())
  model.add(layers.Dense(1))
  return model


discriminator=make_discrimanarator_model()
discriminator.summary()


# checking output of generated image
# note - neither this output nor the above generated image make any sense because model is not trained
discriminator(generated_image,training=False)


# defining loss function
cross_entropy=tf.keras.losses.BinaryCrossentropy(from_logits=True)





# eg
tf.zeros_like([1,2,3])


def discriminator_loss(real_output,fake_ouput):
  real_loss=cross_entropy(tf.ones_like(real_output),real_output)
  fake_loss=cross_entropy(tf.zeros_like(fake_ouput),fake_ouput)
  return fake_loss+real_loss





def generator_loss(fake_ouput):
  loss=cross_entropy(tf.ones_like(fake_ouput),fake_ouput)
  return loss





generator_optimizer=tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer=tf.keras.optimizers.Adam(1e-4)





import os
checkpoints_dir='./training_checkpoints'
if not os.path.exists(checkpoints_dir):
  os.makedirs(checkpoints_dir)

# This TensorFlow-style checkpoint saves weights + optimizer states seprately for both â€” useful for custom training loops.
checkpoint=tf.train.Checkpoint(generator_optimizer=generator_optimizer,discriminator_optimizer=discriminator_optimizer,generator=generator,discriminator=discriminator)


EPOCHS=100
noise_dim=100
num_examples_to_generate=16

# seed
seed=tf.random.normal([num_examples_to_generate,noise_dim])


seed.shape


# @tf.function is a decorator which tells tf to complie this fn as graph for faster execution


# training function
@tf.function
def train_step(images):
  noise=tf.random.normal([BATCH_SIZE,noise_dim])

  with tf.GradientTape() as gen_tape,tf.GradientTape() as dis_tape:
    generated_images=generator(noise,training=True)

    real_output=discriminator(images,training=True)
    fake_output=discriminator(generated_images,training=True)

    gen_loss=generator_loss(fake_output)
    disc_loss=discriminator_loss(real_output,fake_output)

    # it calculates gradients
  gradients_of_generator=gen_tape.gradient(gen_loss,generator.trainable_variables)
  gradients_of_discriminator=dis_tape.gradient(disc_loss,discriminator.trainable_variables)

    # updating weigths
  generator_optimizer.apply_gradients(zip(gradients_of_generator,generator.trainable_variables))
  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,discriminator.trainable_variables))


def generate_and_save_images(model,epoch,test_input):
  predictions=model(test_input,labels=False)

  # rescalling images from -1to1 to 0to1
  predictions=(predictions+1)/2

  fig=plt.figure(figsize=(4,4))

  for i in range(predictions.shape[0]):
    plt.subplot(4,4,i+1)
    plt.imshow(predictions[i,:,:,0],cmap='gray')
    plt.axis('off')

  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))
  plt.show()


import time
def train(dataset,epochs):
  for epoch in range(epochs):
    start_time=time.time()

    for image_batch in dataset:
      train_step(image_batch)

    generate_and_save_images(generator,epoch+1,seed)

    if (epoch+1)%15==0:
      checkpoint.save(file_prefix=checkpoints_dir)

    print("time taken for epoch {} is {} sec".format(epoch+1,time.time()-start_time))

  generate_and_save_images(generator,EPOCHS,seed)



train(train_dataset,EPOCHS)


# restoring the latest checkpoint
checkpoint.restore(tf.train.latest_checkpoint(checkpoints_dir))

import PIL

def display_image(epoch_no):
   return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))

display_image(EPOCHS)


# Creating gif


import imageio
import glob

anim_file='gan.gif'

with imageio.get_writer(anim_file,mode='I') as writer:
  filenames=glob.glob('image_at_epoch*.png')
  filenames=sorted(filenames)
  for filename in filenames:
    image=imageio.imread(filename)
    writer.append_data(image)
  # appending last image multiple time for a pause at end
  for i in range(10):
    writer.append_data(image)




