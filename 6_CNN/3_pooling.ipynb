{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7719af-6cea-46ca-8634-1c98423004f1",
   "metadata": {},
   "source": [
    "## CNN Lecture 5: The Pooling Layer\n",
    "\n",
    "### I. Introduction and Definition\n",
    "\n",
    "The Pooling Layer is an essential component of a CNN architecture, typically added **right after a Convolutional Layer**.\n",
    "\n",
    "*   **Operation Type:** Pooling is fundamentally a **downsampling operation**.\n",
    "*   **Purpose:** The primary goal of pooling is to **reduce the size of the feature map**.\n",
    "*   **Trainability:** Pooling layers have **zero trainable parameters** because they function purely as an aggregate operation.\n",
    "\n",
    "### II. Necessity: Problems Solved by Pooling\n",
    "\n",
    "Pooling is used to address two major issues that arise after standard convolution operations:\n",
    "\n",
    "#### A. Memory Issues\n",
    "*   Convolution generates large **feature maps** that require a significant amount of memory storage (RAM).\n",
    "*   If the feature maps are too large (e.g., a $228 \\times 228 \\times 100$ feature map), the memory requirement for even a single training datum can be substantial (around 900MB), potentially causing the program to **crash**.\n",
    "*   Pooling actively reduces the size of the feature map, thereby mitigating these storage demands.\n",
    "\n",
    "#### B. Translation Variance\n",
    "*   Standard convolution operations exhibit **Translation Variance**. This means that the features detected are **location dependent**.\n",
    "*   If a specific feature (like a cat's ear) slightly shifts position within the image, subsequent layers will treat it as a different feature.\n",
    "*   For tasks like **image classification**, the specific location of a feature does not matter; only the presence of the feature matters.\n",
    "*   Pooling solves this by ensuring **Translation Invariance**. By downsampling the feature map, the features become **location independent**.\n",
    "\n",
    "### III. How Pooling Works (Mechanism and Types)\n",
    "\n",
    "Pooling is applied to individual feature maps after the non-linear activation (like ReLU) is applied.\n",
    "\n",
    "<a href=\"https://deeplizard.com/resource/pavq7noze3\">See demo here</a>\n",
    "#### A. Required Configuration\n",
    "To define a pooling operation, three elements must be specified:\n",
    "1.  **Size of the window (Pool Size):** Commonly $2 \\times 2$, but can be changed.\n",
    "2.  **Stride Value:** Often set to 2, but customizable.\n",
    "3.  **Type of Pooling** (e.g., Max, Mean).\n",
    "\n",
    "#### B. Max Pooling (The Most Used Type)\n",
    "*   The filter (window) is placed over a section of the feature map.\n",
    "*   The operation extracts the **single maximum value** from the numbers within that window. This maximum value is considered the most **dominant feature** in that small local receptive field.\n",
    "*   Example: A $4 \\times 4$ feature map processed by a $2 \\times 2$ Max Pooling operation with a stride of 2 will result in a $2 \\times 2$ feature map.\n",
    "*   By keeping only the dominant features, Max Pooling eliminates low-level details, helping to achieve translation invariance.\n",
    "\n",
    "#### C. Other Types of Pooling\n",
    "*   **Mean/Average Pooling:** Calculates the **average** of the numbers within the pooling area.\n",
    "*   **L2 Pooling:** Uses the L2 norm (Euclidean distance).\n",
    "*   **Global Pooling Layers:** These operate on the **entire feature map**.\n",
    "    *   **Global Max Pooling:** Extracts the maximum value from the entire map, resulting in a single number per map.\n",
    "    *   **Global Average Pooling:** Calculates the average of all numbers in the map, resulting in a single number per map. Global Pooling is often used near the end of the CNN to **reduce overfitting** before passing data to the Fully Connected Layer.\n",
    "\n",
    "#### D. Operation on Multi-Channel Data\n",
    "If working with a volume (tensor) composed of multiple feature maps (e.g., $4 \\times 4 \\times 33$ feature maps), pooling is applied **individually** to each feature map. The depth/volume size remains unchanged after pooling (e.g., $4 \\times 4 \\times 33$ becomes $2 \\times 2 \\times 33$).\n",
    "\n",
    "### IV. Advantages of Pooling\n",
    "\n",
    "1.  **Significant Size Reduction:** Pooling dramatically shrinks the size of the feature map. This is particularly noticeable when comparing the input feature map size (e.g., $226 \\times 226 \\times 100$) to the pooled output size (e.g., $113 \\times 113 \\times 100$).\n",
    "2.  **Translation Invariance:** It helps the CNN model focus on **higher-level features** and ignore low-level details, ensuring the model identifies a feature regardless of its exact position.\n",
    "3.  **Enhanced Features (Specific to Max Pooling):** Because Max Pooling extracts the most dominant features, the resulting features in the map can appear **enhanced** (e.g., brighter).\n",
    "4.  **No Training Required:** Since pooling is a simple aggregate function (max/average extraction), there is **no need for training** using backpropagation, making the layer fast. It is considered faster than relying on high stride values in convolution to reduce size.\n",
    "\n",
    "### V. Disadvantages of Pooling\n",
    "\n",
    "1.  **Loss of Information:** Pooling eliminates a considerable amount of data. When a $4 \\times 4$ area is reduced to $2 \\times 2$, only one number is kept out of four (25%), meaning the operation effectively **loses around 75% of the information**.\n",
    "2.  **Unsuitable for Location-Dependent Tasks:** For computer vision tasks where the exact location of a feature is critical (e.g., **Image Segmentation**), the use of pooling is limited or avoided because it sacrifices location information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e4abd6-3056-43cc-ac34-653ab5fbe4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,144</span> (39.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,144\u001b[0m (39.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,144</span> (39.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,144\u001b[0m (39.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "\n",
    "# eg model\n",
    "model=Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(50,50,3)))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
