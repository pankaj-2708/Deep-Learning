{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e09f24e0-c173-4d74-b1aa-1b0eceaa084f",
   "metadata": {},
   "source": [
    "## Lecture Notes: Pre-trained Models in CNNs\n",
    "\n",
    "### I. The Need for Pre-trained Models (Transfer Learning Context)\n",
    "\n",
    "Deep Learning models, especially CNNs used for image classification, require vast amounts of data to perform well; this characteristic is described as **\"data hungry\"**.\n",
    "\n",
    "**Challenges of Training Custom Models:**\n",
    "\n",
    "1.  **Data Acquisition and Labeling:** Obtaining large quantities of image data (e.g., 10,000 photos) is difficult, and manually labeling that data (e.g., specifying if a photo is a dog or a cat) is a **tedious task**. Manual labeling requires time, or the hiring of staff, resulting in potential **financial loss**.\n",
    "2.  **Training Time:** Training models on huge datasets requires significant time, often taking **hours, days, or even weeks**, making the overall model building process slow.\n",
    "\n",
    "**Solution: Pre-trained Models**\n",
    "Pre-trained models are CNN architectures or other neural network architectures that have been built by someone else and trained on a different dataset. These models are so robust that they can be used for new problems.\n",
    "\n",
    "**Benefits of Using Pre-trained Models:**\n",
    "\n",
    "*   **Saves Training Time:** You do not have to conduct full training.\n",
    "*   **Reduced Data Need:** You do not need to secure a massive amount of data; even if you have **zero data** or **very little data**, the pre-trained model can still be utilized.\n",
    "\n",
    "### II. The Foundation: ImageNet Dataset and ILSVRC\n",
    "\n",
    "The concept of pre-trained models stems from the **ImageNet dataset**.\n",
    "\n",
    "**ImageNet Dataset Details:**\n",
    "\n",
    "*   **Definition:** ImageNet is a visual database of images.\n",
    "*   **Scale:** It contains 1.4 million images (or 1.4 crore images, in Indian terms).\n",
    "*   **Content:** It covers approximately **20,000 categories** of daily household items and common items seen daily, such as cats, dogs, vehicles, tables, and chairs.\n",
    "*   **Labeling:** The images are well-organized and labeled, often including the specific breed (e.g., a specific breed of dog) and sometimes featuring **bounding box labeling** to show object location (useful for object localization tasks).\n",
    "*   **Creation Method:** The dataset was built using **crowd help** and a service by Amazon called **Mechanical Turk**.\n",
    "\n",
    "**The ImageNet Large Scale Visual Recognition Challenge (ILSVRC)**\n",
    "\n",
    "*   **Start:** The competition, also known as the ImageNet Challenge, started in 2010.\n",
    "*   **Goal:** To surface the best image classification models.\n",
    "*   **Competition Dataset:** A subset of the original ImageNet data was used, containing **1 million images** and **1,000 classes** (down from the 20,000 classes in the full ImageNet dataset).\n",
    "\n",
    "### III. The Deep Learning Revolution (2010–2016)\n",
    "\n",
    "The ILSVRC charted the progress of computer vision systems:\n",
    "\n",
    "| Year | Model Type | Winning Model/Architecture | Error Rate | Notes |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| 2010 | Machine Learning | N/A | **28%** | Models relied on manual feature extraction. |\n",
    "| 2011 | Machine Learning | N/A | **25%** | Minor improvement. |\n",
    "| 2012 | Deep Learning (CNN) | **AlexNet** | **16.4%** | This was a revolutionary moment, improving over the second place by more than 10%. It used ReLU activation and focused the entire tech world's attention on CNNs. |\n",
    "| 2013 | Deep Learning (CNN) | **ZFNet** | **11.7%** | Continued improvement. |\n",
    "| 2014 | Deep Learning (CNN) | **VGG (Visual Geometry Group)** | **7.3%** | Became a very famous architecture used widely. |\n",
    "| 2015 | Deep Learning (CNN) | **GoogLeNet** | **6.7%** |. |\n",
    "| 2016 | Deep Learning (CNN) | **ResNet** | **3.5%** | This architecture surpassed the average human error rate, which is typically around 5%. |\n",
    "\n",
    "**Key Trend:** As the years progressed, researchers consistently added **more layers** to the CNN models, increasing complexity, which resulted in a **reduction in the error rate**.\n",
    "\n",
    "**AlexNet Architecture (2012 Winner):**\n",
    "\n",
    "*   Input images were $227 \\times 227$ colored images.\n",
    "*   The first layer used 96 filters of $11 \\times 11$ size.\n",
    "*   It used max pooling with a size of $3 \\times 3$ and a stride of 2.\n",
    "*   The final stage included three fully connected layers, with 1,000 units (for 1,000 classes).\n",
    "\n",
    "### IV. Using Pre-trained Models in Keras\n",
    "\n",
    "The Keras library provides many pre-trained models ready for use.\n",
    "\n",
    "**Available Models:**\n",
    "\n",
    "Keras Applications lists various famous pre-trained models, including:\n",
    "\n",
    "*   **VGG16** (16 layers) and **VGG19** (19 layers)\n",
    "*   **ResNet50** and **ResNet50 V2**\n",
    "*   **Xception**\n",
    "*   **MobileNet** (known for being light-weight)\n",
    "*   **Inception V3**\n",
    "\n",
    "**Model Characteristics (VGG16 vs. ResNet50):**\n",
    "\n",
    "*   **VGG16** is large, around **528 MB**, containing roughly **130.4 million parameters** (weights/numbers stored).\n",
    "*   **ResNet50** is more light-weight, around **98 MB**, with fewer parameters.\n",
    "\n",
    "**Accuracy Metrics:**\n",
    "\n",
    "*   **Top 1 Accuracy:** Accurately identifying the single correct classification of the image.\n",
    "*   **Top 5 Accuracy:** The correct answer is included within the model’s top five predictions.\n",
    "\n",
    "**Keras Implementation Example (ResNet50):**\n",
    "\n",
    "1.  **Loading the Model:** Import the model (e.g., `ResNet50`) and load it, specifying the required weights: `weights='imagenet'`. This ensures the model uses the weights obtained after training on the ImageNet dataset.\n",
    "2.  **Processing Input:** Images are loaded, converted to a batch, and processed.\n",
    "3.  **Prediction:** The processed image is sent to the model for prediction.\n",
    "4.  **Decoding:** The raw output is decoded to display human-readable predictions (e.g., showing not just 'dog' but 'Labrador Retriever' or 'Golden Retriever').\n",
    "\n",
    "Using this method, one can create a **\"universal classifier\"** that can predict the content of various input images (e.g., dog, bread, tomato, chair) without requiring the user to build and train their own custom architecture.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccd02a92-8621-443c-8d10-fad9bb8c0fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102967424/102967424 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = './test_set/test_set/cats/cat.4001.jpg'\n",
    "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "x = keras.utils.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065fbea0-2ffe-48c4-9bc8-6ed1bf6d6e83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "35363/35363 [==============================] - 0s 1us/step\n",
      "Predicted: [('n03598930', 'jigsaw_puzzle', 0.67379516), ('n02123597', 'Siamese_cat', 0.11601709), ('n04589890', 'window_screen', 0.10092571)]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl_py_9)",
   "language": "python",
   "name": "dl_py_9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
